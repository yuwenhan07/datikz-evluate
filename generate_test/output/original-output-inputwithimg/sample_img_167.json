{
  "prompt": "The interaction diagram of the agents and the MEC environment. Client agents output their actions $\\{x_{n}, p_n, f_{n}\\}$. Clients with $\\{ x_{c,n} < 0.5$\\} start local processing; and the others propose their tasks to the master agent, who makes the combinatorial decision on which of the proposed tasks should be offloaded and which of them should be designated for local processing",
  "final_latex_code": "\\documentclass[border=10pt]{standalone}\n\\usepackage{tikz}\n\\usetikzlibrary{positioning}\n\n\\begin{document}\n\n\\begin{tikzpicture}[scale=0.8]\n    % Define node styles\n    \\tikzset{\n        block/.style={draw, rectangle, minimum height=3em, minimum width=6em},\n        line/.style={draw, -latex'},\n        dashedline/.style={draw, densely dashed, -latex'},\n    }\n\n    % Draw the main box\n    \\node [block] (client_environment) at (0,0) {};\n    \\node [block, below=of client_environment.south west, anchor=north west, node distance=2cm, minimum width=4cm] (client1) {Client agent 1};\n    \\node [block, below=of client1.south, node distance=2cm, minimum width=4cm] (client2) {Client agent 2};\n    \\node [block, below=of client2.south, node distance=2cm, minimum width=4cm] (clientN) {Client agent N};\n    \\node [block, right=3cm of client1] (master_agent) {Master agent};\n    \\node [block, right=3cm of client2] (mece_env) {MEC Environment \\\\ (UDs & Server)};\n\n    % Draw dashed lines for policies\n    \\draw[dashedline] (client1.north east) -- ++(0.5,0) node [right] {Policy 1 ($\\theta_1$)};\n    \\draw[dashedline] (client2.north east) -- ++(0.5,0) node [right] {Policy 2 ($\\theta_2$)};\n    \\draw[dashedline] (clientN.north east) -- ++(0.5,0) node [right] {Policy N ($\\theta_N$)};\n\n    % Draw arrows for client actions\n    \\draw[line] (client1.east) -- ++(1,0) node [right] {client-actions$\\{x_{n},p_n,f_{n}\\}$} |- (mece_env.west);\n    \\draw[line] (client2.east) -- ++(1,0) |- (mece_env.west);\n    \\draw[line] (clientN.east) -- ++(1,0) |- (mece_env.west);\n\n    % Draw arrows for reward\n    \\draw[line] (mece_env.south) -- ++(0,-1) node [below] {reward} -| (master_agent.north east);\n\n    % Draw arrows for master actions\n    \\draw[line] (master_agent.east) -- ++(1,0) node [right] {Master-action$\\{x_{m,n},p_n,f_{n}\\}$} |- (mece_env.west);\n\n    % Draw arrow for TD error\n    \\draw[line] ([yshift=-1em]client_environment.south) -- ++(0,-1) node [below] {TD error} |- (master_agent.north east);\n\n    % Add labels for states\n    \\node [above] at (client1.north east) {$S_1$};\n    \\node [above] at (client2.north east) {$S_2$};\n    \\node [above] at (clientN.north east) {$S_N$};\n    \\node [above] at (mece_env.north east) {$S$};\n\\end{tikzpicture}\n\n\\end{document}",
  "compiled_successfully": true,
  "ground_truth": "\\documentclass{article}\n\\usepackage{tikz}\n\\usetikzlibrary{positioning, arrows, calc, shapes.multipart}\n\\usetikzlibrary{decorations.pathreplacing}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{tikzpicture}[ node distance=2.5cm, every node/.style={align=center}]\n  % Nodes\n  \\node (actor1) [draw, minimum width=1cm, minimum height=2cm, rectangle] {Client agent 1 \\\\ \\tikz \\draw[dotted] (0,0) -- (2,0); \\\\  Policy 1 ($\\theta_1$)};\n  \\node (actor2) [draw, minimum width=1cm, minimum height=2cm, below of=actor1, rectangle] {Client agent 2 \\\\ \\tikz \\draw[dotted] (0,0) -- (2,0); \\\\  Policy 2 ($\\theta_2$)};\n  \\node (actordots) [below of=actor2, node distance=1.5cm] {\\vdots};\n  \\node (actorn) [draw, minimum width=1cm, minimum height=2cm, below of=actordots, node distance=1.5cm, rectangle] {Client agent $N$ \\\\ \\tikz \\draw[dotted] (0,0) -- (2,0); \\\\  Policy N ($\\theta_N$)};\n  \\node (critic) [draw, minimum width=1cm, minimum height=2cm, below right of= actorn, node distance=5.2cm, rectangle] {Master agent\\\\ \\tikz \\draw[dotted] (0,0) -- (2,0); \\\\  Value Function ($\\phi$)};\n  \\node (environment) [draw, minimum width=3cm, minimum height=8cm, right of= actordots, node distance=9cm] {MEC \\\\Environment \\\\\n  \\\\(UDs \\& Server)};\n\n  % actor arrows\n  \\draw [->] (actor1.east) -- ++ (0,0cm) -- ++ (1cm,0) |-  (critic.west);\n  \\draw [->] (actor2.east) -- ++ (0,0cm) -- ++ (1cm,0) |-  (critic.west);\n  \\draw [->] (actorn.east) -- ++ (0,0cm) -- ++ (1cm,0) |- node[pos=0.1, above, rotate=270, anchor=south] {client-actions{$\\{ x_{c,n}, p_n, f_{n}\\}$}} (critic.west);\n  \\draw [->] (actor1.east) -- ++ (1cm,0) |- node[pos=0.75, above] {client-actions{$\\{x_{n}, p_n, f_{n}\\}$}} (environment.west);\n  \\draw [->] (actor2.east) -- ++ (1cm,0) |- (environment.west);\n  \\draw [->] (actorn.east) -- ++ (1cm,0) |- (environment.west);\n  \\draw [->] (critic.east) -- ++ (1.5cm, 0cm)  -| node[pos=0.25, below] {Master-action {$\\{x_{m,n}, p_n, f_{n}\\}$}} (environment.south);\n\n  % state arrows\n  \\draw [->] (environment.north) -- ++(0,1cm) -|node[pos=0, above] {$S$} node[pos=1, left] {$S_1$}([xshift=-1cm]actor1.west) |- (actor1.west);\n  \\draw [->] (environment.north) -- ++(0,1cm) -|node[pos=1, left] {$S_2$} ([xshift=-1cm]actor2.west) |- (actor2.west);\n  \\draw [->] (environment.north) -- ++(0,1cm) -|node[pos=1, left] {$S_N$} ([xshift=-1cm]actorn.west) |- (actorn.west);\n  \\draw [->] (environment.north) -- ++(0,1cm) -| ([xshift=-7cm]critic.west) |- (critic.west);\n  \\draw [->] (environment.south west) -- ++(0,1cm) -| ([xshift=-0cm]critic.north) node[pos=0.25, above] {reward};\n\n  % TD error\n  \\draw [->] (critic.south) -- ++(0,-0.25cm) -- ++(-6cm,0) |- ([yshift=-0.25cm] actor1.south) node[pos=0, left] {TD error} -- (actor1.south);\n  \\draw [->] (critic.south) -- ++(0,-0.25cm) -- ++(-6cm,0) |- ([yshift=-0.25cm] actor2.south) -- (actor2.south);\n  \\draw [->] (critic.south) -- ++(0,-0.25cm) -- ++(-6cm,0) |- ([yshift=-0.25cm] actorn.south) -- (actorn.south);\n\n\\end{tikzpicture}\n\n\\end{document}",
  "attempts": 1
}