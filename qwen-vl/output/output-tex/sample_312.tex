It seems like you're comparing the performance of your approach against state-of-the-art (SoTA) real-time object detection models. Here's a structured breakdown of the information provided:

1. **Performance Comparison**: Your approach is claimed to outperform previous SoTA real-time detectors.
2. **Metrics**:
   - The x-axis represents the inference time.
   - The y-axis represents the mean Average Precision (mAP) score on the COCO `val2017` dataset.
3. **Training Details**: All models were trained using pretraining on Objects365.
4. **Post-Processing Times**: 
   - For other models, the NMS (Non-Maximum Suppression) post-processing times are included.
   - These times are measured on the COCO `val2017` dataset using the settings from the official implementations of the respective models (`lyu2022rtmdet`, `yolov8_ultralytics`, and `supergradients`).
   - A well-tuned NMS post-processing setting is also included and labeled as ``*``.

This setup allows for a fair comparison of the models' performance in terms of both speed (inference time) and accuracy (mAP score). If you have any specific questions or need further clarification on this, feel free to ask!